---
title:  "(TIL) 챗봇 프로젝트 - RAG"
excerpt: "# 챗봇 프로젝트
한 모델에 해리포터의 모든 대사를 한꺼번에 학습시킬 경우:
  - 특정 캐릭터 말투 희석: 모든 캐릭터의 말투가 혼합되어 학습되므로, 특정 캐릭터의 말투가 희석될 수 있습니다. 즉, 각 캐릭터의 특징적인 말투를 명확하게 나타내지 못할 수 있다."

categories:
  - TIL
tags:
  - [AI, 딥러닝, 파이썬, 자연어 처리, NLP]

toc: true

last_modified_at: 2025-01-20
thumbnail: ../images/TIL.png
---
![](/images/../images/TIL.png)

# 챗봇 프로젝트
한 모델에 해리포터의 모든 대사를 한꺼번에 학습시킬 경우:
  - 특정 캐릭터 말투 희석: 모든 캐릭터의 말투가 혼합되어 학습되므로, 특정 캐릭터의 말투가 희석될 수 있습니다. 즉, 각 캐릭터의 특징적인 말투를 명확하게 나타내지 못할 수 있다.
  - 데이터 불균형 문제 발생 가능: 특정 캐릭터의 대사 데이터가 다른 캐릭터보다 훨씬 많은 경우, 모델이 해당 캐릭터의 말투에 편향될 수 있다.

=> 그래서 나는 각 모델에 각자의 캐릭터 대사만 학습시켜 파인튜닝했다. 그런데 이렇게 했더니 '각 모델은 자신의 캐릭터에 대한 정보만 학습한다'는 문제가 있었다.

## RAG
다시 말해, 각자의 대사만 학습한 챗봇은 그럴듯한 말투의 답변을 내놓긴 하지만, 실질적인 내용이 사실과 관계가 없는 hallucination 문제가 있었다. 따라서 정확한 근거로 답변을 생성하는 방법으로 RAG라는 기법을 사용하기로 했다.

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F3iDWm%2FbtsHCsABTya%2FvAwlgpE3KKDWN8qXLp7DLK%2Fimg.png)

기존의 LLM과 비교해 봤을 때, 사용자의 Query와 함께 관련된 데이터를 외부 데이터베이스로부터 검색하는 단계가 추가되어야 한다. 이렇게 검색된 데이터를 Query와 함께 LLM에 입력하면, 해당 정보를 기반으로 답변을 생성해 줄 수 있게 된다.     
참고 자료: [RAG | 현대자동차 챗봇 구현기](https://rimo.tistory.com/42)

## ANN(Approximate Nearest Neighbor) 알고리즘
벡터 DB에 있는 수많은 벡터들에 대해서 각각 유사도(예: 코사인 유사도)를 다 측정하게 되면 시간이 엄청 오래 걸린다. 이 문제를 해결할 수 있는 알고리즘이 바로 ANN(Approximate Nearest Neighbor) 알고리즘이다.

여기서는 임베딩 벡터 저장소 구축에 `MilvusVectorStore`를 사용해보려고 한다.

- `vector_store = MilvusVectorStore(...)`: Milvus라는 벡터 데이터베이스를 사용하여 임베딩 벡터를 저장
    - `uri`: Milvus 서버 주소
    - `collection_name`: 컬렉션 이름
    - `dim`: 임베딩 차원
    - `similarity_metric`: 유사도 측정 방식
    
해리포터 위키 텍스트의 임베딩을 저장할 저장소를 구축하는 부분으로, 다른 벡터 데이터베이스(Faiss, Annoy 등)를 사용할 수도 있다.

-  Milvus supports several similarity search types, including top-k approximate nearest neighbor (ANN) and range ANN.
- Most of Milvus's retrieval methods support ANNS (Approximate Nearest Neighbors Search), which is a technique used to speed up vector retrieval.

Hugging Face에서 제공하는 Sentence Transformer를 사용할 것이다. 
all-MiniLM-L6-v2는 Sentence-BERT 계열 모델 중 속도가 매우 빠른 편이다. 무료로 사용할 수 있으며, 상업적인 용도로도 사용 가능하다.

속도가 중요하고 리소스가 제한적인 환경에서 사용하기에 적합하며, 무료로 사용할 수 있다는 장점까지 가지고 있다. 하지만 속도를 위해 어느 정도의 성능 손실이 있기 때문에, 높은 정확도가 최우선이라면 all-mpnet-base-v2와 같은 더 큰 모델을 고려해볼 수 있다.