---
title:  "(TIL) LLM 특강 4"
excerpt: "MLP(다층 퍼셉트론) 퍼셉트론은 선형 모델이어서 분류를 하지 못하는 문제가 있음. 예: XOR 문제"

categories:
  - Deep Learning
tags:
  - [AI, 딥러닝, 파이썬, 자연어 처리, NLP]

toc: true

last_modified_at: 2025-02-07
thumbnail: ../images/TIL.png
---
![](/images/../images/TIL.png)

# LLM 특강 4

MLP(다층 퍼셉트론)

퍼셉트론은 선형 모델이어서 분류를 하지 못하는 문제가 있음. 예: XOR 문제
-> 여러 층을 쌓으면 해결 가능

## 트랜스포머 탄생 배경
MLP의 한계:                 
- 기존의 MLP는 단순한 구조를 연결해놓은 것이어서 고정된 길이의 입력 데이터는 잘 처리함
- BUT 자연어처럼 길이가 다양하거나, 앞뒤 흐름을 고려해야하는 데이터에서는 잘 동작하지 않음
    - WHY?      
    입력 데이터의 순서를 고려하는 기술이 들어있지 않기 때문! 그저 각각의 입력 데이터를 숫자(벡터)로 보고 독립적으로 처리한다.

RNN의 문제:      
1. 장기 의존성 문제
- 문장이 길어지면 길어질수록 과정의 정보보다 최근의 단어들에만 집중
2. 기울기 소실 문제
- RNN은 학습시킬 때 역전파를 통해 가중치를 업데이트함
- 이 과정에서 문장이 길어지면 초기 단어들의 영향력이 점점 감소
3. 매우 느림
- 단어 하나하나를 모두 연산해야 해서 속도가 매우 느림

=> 긴 문장 학습이 불가

대안:       
- LSTM: 중요한 정보를 오래 기억하고 필요없는 정보를 버리는 'GATE' 추가
- GRU: LSTM을 더 간단하게!

=> 그러나 여전히 너무 느리다. 자연어는 매우 긴 데이터이다보니..

트랜스포머      
- 핵심 기술: 어텐션
    - 각 단어가 문장의 다른 단어들과 얼마나 관련이 있는지를 계산

GPU는 대규모 병렬 연산이 가능 -> 행렬 연산이 뛰어남!

1.      
2. RNN/LSTM은 긴 문맥을 기억하기 어려움         
=> 트랜스포머 시대 이전에는 사전 훈련을 하는 것이 어렵고 크게 의미가 없었음
=> 각각의 도메인에 대한 개별적인 NLP 모델을 따로 처음부터 훈련해야 했음

=> 하지만 트랜스포머 이후에는 ~한 LLM이 등장할 수 있었다.

---

+a. 

온프레미스(On-premise)      
: 기업이 자체적으로 서버를 구축하고 운영하는 방식.      
클라우드와 대비되는 개념으로, 기업이 하드웨어와 소프트웨어를 구입하여 직접 인프라를 구성하는 것을 의미

- ollama run llama3.1:8b